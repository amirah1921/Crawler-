import scrapy
from newspaper import Article
from datasource.items import DatasourceItem
class MalwaretripwireSpider(scrapy.Spider):
    name = "malwarespider"
    custom_settings = {
        'ROBOTSTXT_OBEY': False,
        'DOWNLOAD_DELAY' : 2,
        'CONCURRENT_REQUESTS': 3
    }
    allowed_domains = ["www.tripwire.com"]
    start_urls = ["https://www.tripwire.com/state-of-security?s=malware"]

    def parse(self, response):
        cont = True
        news = response.css('div.views-row')
        urlList = []
        for n in news:
            title = n.css('h3.node--title::text').get()
            url = n.css('span article div div div a::attr(href)').get()
            postedDate = n.xpath('./div/span/article/div/div/div[2]/div[2]/text()[2]').get()
            author = n.xpath('./div/span/article/div/div/div[2]/div[2]/a/text()').get()

            yield response.follow(url, callback=self.parse_article, meta={
                'title': title,
                'url': url,
                'postedDate': postedDate,
                'author': author,
            })
            urlList.append(url)

        # Process each URL from the list
        for url in urlList:
            yield response.follow(url, callback=self.parse_article)
        
        next_page = response.css('li.pager__item--next a::attr(href)').get()
        if next_page is not None:
            if 'page=' in next_page:
                next_page_url = 'https://www.tripwire.com/state-of-security?s=malware' + next_page
            else:
                next_page_url = 'https://www.tripwire.com/state-of-security?s=malware&page=' + next_page
            yield response.follow(next_page_url, callback=self.parse)
            
    def parse_article(self, response):
        article = Article(response.url, language="en")
        article.download()
        article.parse()

        yield {
            'title': response.meta['title'],
            'url': response.url,
            'postedDate': response.meta['postedDate'],
            'author': response.meta['author'],
            'articleText': article.text,
        }
