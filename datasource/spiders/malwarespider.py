import scrapy
from newspaper import Article
from datasource.items import DatasourceItem

class MalwarespiderSpider(scrapy.Spider):
    name = "malwarespider"
    allowed_domains = ["packetstormsecurity.com"]
    start_urls = ["https://packetstormsecurity.com/news/tags/malware/"]

    def parse(self, response):
        news_items = response.css('dl.news')
        urlList = []
        for news_item in news_items:
            title = news_item.css('dt a::text').get()
            url = news_item.css('dt a::attr(href)').get()
            source = news_item.css('dd.posted-by a::text').get()
            posted_date = news_item.css('dd.datetime a::text').get()

            yield response.follow(url, callback=self.parse_article, meta={
                'title': title,
                'url': url,
                'source': source,
                'postedDate': posted_date,
            })
            # Collect URLs for later processing
            urlList.append(url)

        # Process each URL from the list
        for url in urlList:
            yield response.follow(url, callback=self.parse_article)

        # Follow the pagination link if available
        next_page = response.css('a[accesskey="]"]::attr(href)').get()
        if next_page is not None:
            yield response.follow(next_page, callback=self.parse) 

    def parse_article(self, response):
        article = Article(response.url, language="en")
        article.download()
        article.parse()

        yield {
            'title': response.meta['title'],
            'source': response.meta['source'],
            'postedDate': response.meta['postedDate'],
            'url': response.url,
            'author': article.authors,
            'articleText': article.text,
        }

